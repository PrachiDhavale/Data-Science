{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7bccfbc-f965-4526-b306-0068516a7678",
   "metadata": {},
   "source": [
    "Missing values are a common issue in machine learning. \n",
    "\n",
    "This occurs when a particular variable lacks data points, resulting in incomplete information and potentially harming the accuracy and dependability of your models. \n",
    "\n",
    "It is essential to address missing values efficiently to ensure strong and impartial results in your machine-learning projects. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef9a5e8-fa5b-4ba4-8a74-b228e8a6df86",
   "metadata": {},
   "source": [
    "# How is a Missing Value Represented in a Dataset?\r\n",
    "\n",
    "Missing values in a dataset can be represented in various ways, depending on the source of the data and the conventions used. Here are some common representations:\n",
    "1. NaN (Not a Number): In many programming languages and data analysis tools, missing values are represented as NaN. This is the default for libraries like Pandas in Python.\n",
    "\n",
    "2. NULL or None: In databases and some programming languages, missing values are often represented as NULL or None. For instance, in SQL databases, a missing value is typically recorded as NULL.\n",
    "\n",
    "3. Empty Strings: Sometimes, missing values are denoted by empty strings (\"\"). This is common in text-based data or CSV files where a field might be left blank.\n",
    "\n",
    "4. Special Indicators: Datasets might use specific indicators like -999, 9999, or other unlikely values to signify missing data. This is often seen in older datasets or specific industries where such conventions were established.\n",
    "\n",
    "5. Blanks or Spaces: In some cases, particularly in fixed-width text files, missing values might be represented by spaces or blank fields.\n",
    "\n",
    "Understanding the representation of missing values in your dataset is crucial for proper data cleaning and preprocessing. Identifying and handling these missing values accurately ensures that your data analysis and machine learning models perform optimally.\r\n",
    "imally.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e53b21-5ed2-42c1-b02e-4e27ee04f669",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e530b62-1ba5-43cd-bc24-cc17405f95eb",
   "metadata": {},
   "source": [
    "# How to Handle Missing Data?\n",
    "Missing data is a common headache in any field that deals with datasets. It can arise for various reasons, from human error during data collection to limitations of data gathering methods. Luckily, there are strategies to address missing data and minimize its impact on your analysis. Here are two main approaches:\n",
    "\n",
    "- Deletion: This involves removing rows or columns with missing values. This is a straightforward method, but it can be problematic if a significant portion of your data is missing. Discarding too much data can affect the reliability of your conclusions.\n",
    "\n",
    "- Imputation: This replaces missing values with estimates. There are various imputation techniques, each with its strengths and weaknesses. Here are some common ones:\n",
    "\n",
    "  1. Mean/Median/Mode Imputation: Replace missing entries with the average (mean), middle value (median), or most frequent value (mode) of the corresponding column. This is a quick and easy approach, but it can introduce bias if the missing data is not randomly distributed.\n",
    " \n",
    "  2. K-Nearest Neighbors (KNN Imputation): This method finds the closest data points (neighbors) based on available features and uses their values to estimate the missing value. KNN is useful when you have a lot of data and the missing values are scattered.\n",
    " \n",
    "  3. Model-based Imputation: This involves creating a statistical model to predict the missing values based on other features in the data. This can be a powerful technique, but it requires more expertise and can be computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b0259-1be8-4a4e-8be2-8b58c18fd3c7",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "872836bd-618d-4f92-8327-a5051658abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e8bf1a6-240e-4672-8ccb-833d11213e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>cgpa</th>\n",
       "      <th>iq</th>\n",
       "      <th>placement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York</td>\n",
       "      <td>6.8</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>5.9</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York</td>\n",
       "      <td>7.4</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>5.8</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city  cgpa     iq  placement\n",
       "0     New York   6.8  123.0          1\n",
       "1  Los Angeles   5.9  106.0          0\n",
       "2      Chicago   NaN  121.0          0\n",
       "3     New York   7.4  132.0          1\n",
       "4  Los Angeles   5.8  142.0          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'Data-Science/placement-dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71338789-b6c3-4b8a-8410-5a8b30db29b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city         0\n",
       "cgpa         8\n",
       "iq           4\n",
       "placement    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if Null values are present in data or not\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ec4204f-6032-47b3-8f41-02ec33cf8455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Null values with mean\n",
    "\n",
    "# for column : cgpa\n",
    "data['cgpa'] = data['cgpa'].fillna(data['cgpa'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12d24829-9874-4aab-a0b1-041baf285028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cgpa'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6421c3df-f987-413c-8651-d1fe0b52360a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column : iq\n",
    "data['iq'] = data['iq'].fillna(data['iq'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b48bf7a-b5c9-48b0-9109-860b977cf5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['iq'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90f671b4-cf44-429b-921f-0e3925afd072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city         0\n",
       "cgpa         0\n",
       "iq           0\n",
       "placement    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c036f5a-ad3f-422c-8c41-b4bde90db982",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb167360-cc17-45bf-b03b-d9c705e0cdd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>cgpa</th>\n",
       "      <th>iq</th>\n",
       "      <th>placement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York</td>\n",
       "      <td>6.8</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>5.9</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York</td>\n",
       "      <td>7.4</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>5.8</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city  cgpa     iq  placement\n",
       "0     New York   6.8  123.0          1\n",
       "1  Los Angeles   5.9  106.0          0\n",
       "2      Chicago   NaN  121.0          0\n",
       "3     New York   7.4  132.0          1\n",
       "4  Los Angeles   5.8  142.0          0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'Data-Science/placement-dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20601578-c9bb-4e67-a453-a5de4b4c7805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city         0\n",
       "cgpa         8\n",
       "iq           4\n",
       "placement    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abd6cc01-b2d7-4f8d-8d18-abf7d8898a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95574eb5-c1a2-4aeb-90b4-e821c2906634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting rows which have null values\n",
    "new_df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3450706d-2127-4503-9b38-62a69a3902c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cffd96-38aa-487c-a1a1-330def293265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28089d5d-eac1-4507-90ea-02451e369bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
